"""
================================================================================
pipeline/self_forcing_training.py - Self-Forcing è®­ç»ƒ Pipeline
================================================================================

ã€æ–‡ä»¶ä½œç”¨ã€‘
å®ç°äº† Self-Forcing çš„æ ¸å¿ƒè‡ªå›å½’ç”Ÿæˆé€»è¾‘ã€‚
åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¿™ä¸ª Pipeline ä¼šè¢«è°ƒç”¨æ¥æ¨¡æ‹Ÿè§†é¢‘ç”Ÿæˆè¿‡ç¨‹ï¼Œä½†æ˜¯å¸¦æœ‰ç‰¹æ®Šçš„ Gradient Checkpointing å’Œ KV Cache é€»è¾‘ã€‚
å®ƒå…è®¸æˆ‘ä»¬åœ¨æ²¡æœ‰çœŸå®è§†é¢‘æ•°æ®çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡è®©æ¨¡å‹"åƒè‡ªå·±çš„ç‹—ç²®"ï¼ˆå³ç”¨è‡ªå·±çš„ç”Ÿæˆç»“æœä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥ï¼‰æ¥è®­ç»ƒæ¨¡å‹ã€‚

ã€æ ¸å¿ƒç‰¹æ€§ã€‘
1. KV Cache ç®¡ç†: æ˜¾å¼åˆå§‹åŒ–å’Œæ›´æ–° KV Cache (self.kv_cache1)ï¼Œé¿å…å¯¹å·²ç»ç”Ÿæˆçš„å¸§é‡å¤è®¡ç®— Attentionã€‚
2. è‡ªå›å½’ç”Ÿæˆå¾ªç¯:
   - å¤–å±‚å¾ªç¯ (Temporal): é€ä¸ª Block (e.g., æ¯ 3 å¸§) ç”Ÿæˆè§†é¢‘ã€‚
   - å†…å±‚å¾ªç¯ (Spatial/Denoising): åœ¨æ¯ä¸ª Block å†…ï¼Œè¿›è¡Œå°‘æ­¥æ•° (e.g., 4æ­¥) å»å™ªã€‚
3. éšæœºé€€å‡ºæœºåˆ¶ (Self-Forcing æ ¸å¿ƒ):
   - ä¸ºäº†èŠ‚çœè®­ç»ƒæ˜¾å­˜å’Œè®¡ç®—ï¼Œæˆ‘ä»¬ä¸åœ¨æ¯ä¸€æ­¥éƒ½åº”ç”¨åå‘ä¼ æ’­ã€‚
   - è€Œæ˜¯éšæœºé€‰æ‹©ä¸€ä¸ªå»å™ªæ­¥æ•° (exit_flag)ï¼Œåªåœ¨è¯¥æ­¥ä¿ç•™æ¢¯åº¦ç”¨äºè®­ç»ƒï¼Œå…¶ä»–æ­¥éª¤ä»…åš torch.no_grad() æ¨ç†ã€‚
================================================================================
"""

from utils.wan_wrapper import WanDiffusionWrapper
from utils.scheduler import SchedulerInterface
from typing import List, Optional
import torch
import torch.distributed as dist


class SelfForcingTrainingPipeline:
    """
    è‡ªå¼ºåˆ¶è®­ç»ƒ Pipelineã€‚
    è´Ÿè´£æ‰§è¡Œå¸¦æœ‰ KV Cache å’Œéšæœºæ¢¯åº¦æ£€æŸ¥ç‚¹çš„è‡ªå›å½’è§†é¢‘ç”Ÿæˆã€‚
    """
    def __init__(self,
                 denoising_step_list: List[int],
                 scheduler: SchedulerInterface,
                 generator: WanDiffusionWrapper,
                 num_frame_per_block=3,
                 independent_first_frame: bool = False,
                 same_step_across_blocks: bool = False,
                 last_step_only: bool = False,
                 num_max_frames: int = 21,
                 context_noise: int = 0,
                 **kwargs):
        """
        Args:
            denoising_step_list: å»å™ªæ­¥æ•°åˆ—è¡¨ï¼Œe.g., [1000, 750, 500, 250]
            scheduler: å™ªå£°è°ƒåº¦å™¨
            generator: ç”Ÿæˆå™¨æ¨¡å‹ (å·²è¢« FSDP åŒ…è£…)
            num_frame_per_block: æ¯æ¬¡ç”Ÿæˆçš„å¸§æ•°å—å¤§å° (é»˜è®¤ä¸º 3)
            kv_cache_size: KV Cache å®¹é‡ï¼Œé¢„åˆ†é…ä»¥é¿å…åŠ¨æ€å†…å­˜åˆ†é…å¼€é”€
        """
        super().__init__()
        self.scheduler = scheduler
        self.generator = generator
        self.denoising_step_list = denoising_step_list
        
        # ç§»é™¤ 0 æ—¶é—´æ­¥ï¼Œå› ä¸º inference åˆ° 0 å°±ç»“æŸäº†ï¼Œä¸éœ€è¦å†ä½œä¸ºè¾“å…¥
        if self.denoising_step_list[-1] == 0:
            self.denoising_step_list = self.denoising_step_list[:-1]

        # Wan æ¨¡å‹ç‰¹å®šå‚æ•°
        self.num_transformer_blocks = 30
        self.frame_seq_length = 1560 # æ¯å¸§çš„ Token æ•°é‡ (patchåŒ–å)
        self.num_frame_per_block = num_frame_per_block
        self.context_noise = context_noise
        self.i2v = False

        self.kv_cache1 = None
        self.kv_cache2 = None
        self.independent_first_frame = independent_first_frame
        self.same_step_across_blocks = same_step_across_blocks
        self.last_step_only = last_step_only
        self.kv_cache_size = num_max_frames * self.frame_seq_length # é¢„åˆ†é…æ˜¾å­˜

    def generate_and_sync_list(self, num_blocks, num_denoising_steps, device):
        """
        ç”Ÿæˆå¹¶åŒæ­¥é€€å‡ºæ ‡å¿— (exit_flags)ã€‚
        è¿™å†³å®šäº†åœ¨æ¯ä¸ª Block çš„ç¬¬å‡ æ­¥å»å™ªæ—¶è®¡ç®—æ¢¯åº¦ã€‚
        å¿…é¡»åœ¨æ‰€æœ‰ GPU é—´åŒæ­¥ï¼Œä»¥ä¿è¯ FSDP æ­£å¸¸å·¥ä½œã€‚
        """
        rank = dist.get_rank() if dist.is_initialized() else 0

        if rank == 0:
            # éšæœºé€‰æ‹©æ¯ä¸ª Block åœ¨å“ªä¸€æ­¥ä¿ç•™æ¢¯åº¦
            indices = torch.randint(
                low=0,
                high=num_denoising_steps,
                size=(num_blocks,),
                device=device
            )
            if self.last_step_only:
                indices = torch.ones_like(indices) * (num_denoising_steps - 1)
        else:
            indices = torch.empty(num_blocks, dtype=torch.long, device=device)

        dist.broadcast(indices, src=0)  # å¹¿æ’­ç»™æ‰€æœ‰è¿›ç¨‹
        return indices.tolist()

    def inference_with_trajectory(
            self,
            noise: torch.Tensor,
            initial_latent: Optional[torch.Tensor] = None,
            return_sim_step: bool = False,
            **conditional_dict
    ) -> torch.Tensor:
        """
        æ‰§è¡Œå¸¦æœ‰è½¨è¿¹è®°å½•çš„æ¨ç†è¿‡ç¨‹ã€‚
        
        Args:
            noise: åˆå§‹çº¯é«˜æ–¯å™ªå£° [B, F, C, H, W]
        Returns:
            output: ç”Ÿæˆçš„è§†é¢‘æ½œå˜é‡ (åŒ…æ‹¬å†å²å¸§çš„è½¨è¿¹)
        """
        batch_size, num_frames, num_channels, height, width = noise.shape
        # è®¡ç®—æ€»å…±æœ‰å¤šå°‘ä¸ª Block éœ€è¦ç”Ÿæˆ
        if not self.independent_first_frame or (self.independent_first_frame and initial_latent is not None):
            assert num_frames % self.num_frame_per_block == 0
            num_blocks = num_frames // self.num_frame_per_block
        else:
            assert (num_frames - 1) % self.num_frame_per_block == 0
            num_blocks = (num_frames - 1) // self.num_frame_per_block
            
        num_input_frames = initial_latent.shape[1] if initial_latent is not None else 0
        num_output_frames = num_frames + num_input_frames  # add the initial latent frames
        
        output = torch.zeros(
            [batch_size, num_output_frames, num_channels, height, width],
            device=noise.device,
            dtype=noise.dtype
        )

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Step 1: åˆå§‹åŒ– KV Cache
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # åˆå§‹åŒ–ä¸ºå…¨é›¶å¼ é‡ï¼Œé¢„åˆ†é…æœ€å¤§æ˜¾å­˜
        self._initialize_kv_cache(
            batch_size=batch_size, dtype=noise.dtype, device=noise.device
        )
        self._initialize_crossattn_cache(
            batch_size=batch_size, dtype=noise.dtype, device=noise.device
        )

        # Step 2: å¤„ç†åˆå§‹ Latent (å¦‚æœæ˜¯ I2V ä»»åŠ¡æˆ–æœ‰æ¡ä»¶è¾“å…¥)
        current_start_frame = 0
        if initial_latent is not None:
            timestep = torch.ones([batch_size, 1], device=noise.device, dtype=torch.int64) * 0
            output[:, :1] = initial_latent
            # è¿è¡Œä¸€æ¬¡ç”Ÿæˆå™¨ï¼Œä»…ä¸ºäº†å¡«å…… KV Cache
            with torch.no_grad():
                self.generator(
                    noisy_image_or_video=initial_latent,
                    conditional_dict=conditional_dict,
                    timestep=timestep * 0, # t=0
                    kv_cache=self.kv_cache1,
                    crossattn_cache=self.crossattn_cache,
                    current_start=current_start_frame * self.frame_seq_length
                )
            current_start_frame += 1

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Step 3: è‡ªå›å½’æ—¶åºç”Ÿæˆå¾ªç¯ (Temporal Loop)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        all_num_frames = [self.num_frame_per_block] * num_blocks
        if self.independent_first_frame and initial_latent is None:
            all_num_frames = [1] + all_num_frames # ç¬¬ä¸€å¸§å¯èƒ½å•ç‹¬ç”Ÿæˆ
            
        # åŒæ­¥éšæœºé€€å‡ºæ ‡å¿—
        num_denoising_steps = len(self.denoising_step_list) # e.g., 4
        exit_flags = self.generate_and_sync_list(len(all_num_frames), num_denoising_steps, device=noise.device)
        
        # ç¡®å®šä»å“ªä¸€å¸§å¼€å§‹è®¡ç®—æ¢¯åº¦ (é€šå¸¸æ˜¯åªå¯¹æœ€åç”Ÿæˆçš„å‡ ä¸ª Block è®¡ç®— Loss)
        # è¿™é‡Œç¡¬ç¼–ç ä¸ºæœ€å 21 å¸§
        start_gradient_frame_index = num_output_frames - 21

        # éå†æ¯ä¸ª Block (e.g., 0, 1, 2, ...)
        for block_index, current_num_frames in enumerate(all_num_frames):
            # è·å–å½“å‰ Block å¯¹åº”çš„æ—¶é—´æ®µå™ªå£°
            noisy_input = noise[
                :, current_start_frame - num_input_frames:current_start_frame + current_num_frames - num_input_frames]

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Step 3.1: ç©ºé—´å»å™ªå¾ªç¯ (Spatial Denoising Loop)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # åœ¨å½“å‰ Block ä¸Šè¿›è¡Œå¤šæ­¥å»å™ª (e.g., 1000 -> 750 -> 500 -> 250)
            for index, current_timestep in enumerate(self.denoising_step_list):
                # åˆ¤æ–­å½“å‰æ­¥æ˜¯å¦æ˜¯é€‰å®šçš„æ¢¯åº¦è®¡ç®—æ­¥
                if self.same_step_across_blocks:
                    exit_flag = (index == exit_flags[0])
                else:
                    exit_flag = (index == exit_flags[block_index])

                timestep = torch.ones(
                    [batch_size, current_num_frames],
                    device=noise.device,
                    dtype=torch.int64) * current_timestep

                if not exit_flag:
                    # ğŸš€ Case A: åªæ¨ç†ï¼Œä¸ä¿ç•™æ¢¯åº¦ (torch.no_grad)
                    with torch.no_grad():
                        _, denoised_pred = self.generator(
                            noisy_image_or_video=noisy_input,
                            conditional_dict=conditional_dict,
                            timestep=timestep,
                            kv_cache=self.kv_cache1, # ä½¿ç”¨ KV Cache åŠ é€Ÿ
                            crossattn_cache=self.crossattn_cache,
                            current_start=current_start_frame * self.frame_seq_length
                        )
                        # å‡†å¤‡ä¸‹ä¸€æ­¥çš„è¾“å…¥: åŠ å™ªå£°åˆ°ä¸‹ä¸€çº§çš„ t
                        next_timestep = self.denoising_step_list[index + 1]
                        noisy_input = self.scheduler.add_noise(
                            denoised_pred.flatten(0, 1),
                            torch.randn_like(denoised_pred.flatten(0, 1)),
                            next_timestep * torch.ones(
                                [batch_size * current_num_frames], device=noise.device, dtype=torch.long)
                        ).unflatten(0, denoised_pred.shape[:2])
                else:
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # ğŸ¯ Case B: è¿™æ˜¯è¢«éšæœºé€‰ä¸­çš„"æ¢¯åº¦æ­¥" (exit_flag == True)
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # 
                    # ã€èƒŒæ™¯çŸ¥è¯†ï¼šä»€ä¹ˆæ˜¯ exit_flagï¼Ÿã€‘
                    # åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ª Block éšæœºé€‰æ‹©äº†ä¸€ä¸ª exit_flagï¼ˆé€€å‡ºæ ‡å¿—ï¼‰ã€‚
                    # ä¾‹å¦‚ï¼Œå»å™ªæ­¥éª¤åˆ—è¡¨æ˜¯ [1000, 750, 500, 250]ï¼Œå…± 4 æ­¥ã€‚
                    # exit_flag å¯èƒ½æ˜¯ 0, 1, 2, æˆ– 3 ä¸­çš„ä»»æ„ä¸€ä¸ªã€‚
                    # 
                    # å½“ index == exit_flag æ—¶ï¼Œå³å½“å‰å»å™ªæ­¥æ˜¯è¢«é€‰ä¸­çš„"æ¢¯åº¦æ­¥"ï¼š
                    # - æˆ‘ä»¬ä¼šåœ¨è¿™ä¸€æ­¥ç”Ÿæˆç»“æœåç«‹å³é€€å‡ºå¾ªç¯ï¼ˆbreakï¼‰
                    # - ä¸å†ç»§ç»­åç»­çš„å»å™ªæ­¥éª¤
                    # 
                    # ã€ä¸ºä»€ä¹ˆè¦éšæœºé€‰æ‹©ä¸€æ­¥é€€å‡ºï¼Ÿã€‘
                    # 1. æ˜¾å­˜èŠ‚çœï¼šå¦‚æœå¯¹æ‰€æœ‰ 4 æ­¥éƒ½ä¿ç•™æ¢¯åº¦ï¼Œæ˜¾å­˜ä¼šçˆ†ç‚¸
                    # 2. Self-Forcing æ ¸å¿ƒæ€æƒ³ï¼šè®­ç»ƒæ—¶æ¨¡æ‹Ÿæ¨ç†çš„"ä¸å®Œç¾"çŠ¶æ€
                    #    - æ¨ç†æ—¶ï¼Œæ¯ä¸€æ­¥çš„è¾“å‡ºéƒ½å¯èƒ½æœ‰è¯¯å·®
                    #    - è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬æ•…æ„ä½¿ç”¨ä¸­é—´æ­¥éª¤çš„è¾“å‡ºï¼ˆè€Œéæœ€ç»ˆå®Œç¾è¾“å‡ºï¼‰
                    #    - è¿™æ ·æ¨¡å‹å­¦ä¼šäº†åœ¨æœ‰è¯¯å·®çš„æƒ…å†µä¸‹ä¹Ÿèƒ½ç»§ç»­ç”Ÿæˆ
                    # 
                    # ã€ä¸¤ç§å­æƒ…å†µçš„åŒºåˆ«ã€‘
                    # æˆ‘ä»¬æŠŠè§†é¢‘åˆ†æˆä¸¤éƒ¨åˆ†ï¼š
                    # - "å†å²åŒºåŸŸ"ï¼šcurrent_start_frame < start_gradient_frame_index
                    #   è¿™äº›æ˜¯è¾ƒæ—©ç”Ÿæˆçš„å¸§ï¼Œä¸å‚ä¸ Loss è®¡ç®—
                    # - "è®­ç»ƒåŒºåŸŸ"ï¼šcurrent_start_frame >= start_gradient_frame_index
                    #   è¿™äº›æ˜¯æœ€å 21 å¸§ï¼Œä¼šå‚ä¸ DMD Loss è®¡ç®—
                    # 
                    # start_gradient_frame_index = num_output_frames - 21
                    # ä¾‹å¦‚ï¼šå¦‚æœæ€»å…±ç”Ÿæˆ 30 å¸§ï¼Œé‚£ä¹ˆ start_gradient_frame_index = 30 - 21 = 9
                    # æ„å‘³ç€ç¬¬ 0-8 å¸§æ˜¯"å†å²åŒºåŸŸ"ï¼Œç¬¬ 9-29 å¸§æ˜¯"è®­ç»ƒåŒºåŸŸ"
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    
                    if current_start_frame < start_gradient_frame_index:
                        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                        # å­æƒ…å†µ B1ï¼šå½“å‰ Block å±äº"å†å²åŒºåŸŸ"
                        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                        # å³ä½¿è¿™æ˜¯è¢«é€‰ä¸­çš„"æ¢¯åº¦æ­¥"ï¼Œä½†å› ä¸ºè¿™äº›å¸§ä¸å‚ä¸ Loss è®¡ç®—ï¼Œ
                        # æ‰€ä»¥æˆ‘ä»¬ä»ç„¶ä½¿ç”¨ torch.no_grad()ï¼Œä¸ä¿ç•™æ¢¯åº¦ã€‚
                        # 
                        # è¿™æ ·åšçš„åŸå› ï¼š
                        # 1. èŠ‚çœæ˜¾å­˜ï¼šæ—©æœŸå¸§çš„æ¢¯åº¦å¯¹ Loss æ²¡æœ‰è´¡çŒ®ï¼Œä¿ç•™å®ƒä»¬åªæ˜¯æµªè´¹æ˜¾å­˜
                        # 2. è®­ç»ƒæ•ˆç‡ï¼šæ¢¯åº¦å›¾è¶ŠçŸ­ï¼Œåå‘ä¼ æ’­è¶Šå¿«
                        # 
                        # ä¸¾ä¸ªä¾‹å­ï¼š
                        # - å‡è®¾ç”Ÿæˆ 30 å¸§ï¼Œæ¯ Block 3 å¸§ï¼Œå…± 10 ä¸ª Block
                        # - start_gradient_frame_index = 9ï¼Œå³åªæœ‰æœ€å 7 ä¸ª Block (ç¬¬ 3-9 å—) çš„å¸§å‚ä¸è®­ç»ƒ
                        # - å‰ 3 ä¸ª Block (ç¬¬ 0-2 å—) çš„å¸§è™½ç„¶ä¹Ÿä¼šè¢«ç”Ÿæˆï¼Œä½†ä¸ä¼šæœ‰æ¢¯åº¦
                        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                        with torch.no_grad():
                            _, denoised_pred = self.generator(
                                noisy_image_or_video=noisy_input,
                                conditional_dict=conditional_dict,
                                timestep=timestep,
                                kv_cache=self.kv_cache1,
                                crossattn_cache=self.crossattn_cache,
                                current_start=current_start_frame * self.frame_seq_length
                            )
                    else:
                        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                        # å­æƒ…å†µ B2ï¼šå½“å‰ Block å±äº"è®­ç»ƒåŒºåŸŸ" â€”â€” è¿™é‡Œæ˜¯çœŸæ­£çš„è®­ç»ƒæ—¶åˆ»ï¼
                        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                        # è¿™é‡Œæ²¡æœ‰ torch.no_grad()ï¼Œæ„å‘³ç€ PyTorch ä¼šè®°å½•å®Œæ•´çš„è®¡ç®—å›¾ã€‚
                        # åç»­çš„ loss.backward() ä¼šæŠŠæ¢¯åº¦ä¸€è·¯ä¼ å›åˆ°è¿™é‡Œçš„ self.generator å‚æ•°ã€‚
                        # 
                        # ã€è¿™ä¸€æ­¥çš„è¾“å‡º denoised_pred ä¼šè¢«ç”¨æ¥å¹²ä»€ä¹ˆï¼Ÿã€‘
                        # 1. é¦–å…ˆï¼Œå®ƒä¼šè¢«è®°å½•åˆ° output å¼ é‡ä¸­ï¼ˆè§ä¸‹é¢çš„ Step 3.2ï¼‰
                        # 2. output æœ€ç»ˆä¼šè¿”å›ç»™ DMD.generator_loss() æˆ– DMD.critic_loss()
                        # 3. Loss å‡½æ•°ä¼šç”¨è¿™ä¸ª output æ¥è®¡ç®—ä¸æ•™å¸ˆæ¨¡å‹çš„åˆ†å¸ƒå·®è·
                        # 4. loss.backward() ä¼šé€šè¿‡è¿™é‡Œçš„ denoised_pred åå‘ä¼ æ’­æ¢¯åº¦
                        # 5. æ¢¯åº¦æœ€ç»ˆåˆ°è¾¾ self.generator çš„æƒé‡ï¼Œè§¦å‘å‚æ•°æ›´æ–°
                        # 
                        # ã€ä¸ºä»€ä¹ˆè°ƒç”¨ self.generator æ—¶æ²¡æœ‰ .backward()ï¼Ÿã€‘
                        # å› ä¸ºè¿™é‡Œåªæ˜¯å‰å‘ä¼ æ’­ï¼ˆforward passï¼‰ã€‚
                        # backward() æ˜¯åœ¨å¤–å±‚çš„ DMD.generator_loss() è¿”å›åç”± Trainer è°ƒç”¨çš„ã€‚
                        # PyTorch çš„è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶ä¼šè®°ä½æ•´ä¸ªè®¡ç®—å›¾ï¼Œå»¶è¿Ÿåˆ° backward() æ—¶ç»Ÿä¸€è®¡ç®—æ¢¯åº¦ã€‚
                        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                        _, denoised_pred = self.generator(
                            noisy_image_or_video=noisy_input,
                            conditional_dict=conditional_dict,
                            timestep=timestep,
                            kv_cache=self.kv_cache1,
                            crossattn_cache=self.crossattn_cache,
                            current_start=current_start_frame * self.frame_seq_length
                        )
                    
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # ğŸ›‘ å…³é”®æ“ä½œï¼šç«‹å³é€€å‡ºå½“å‰ Block çš„å»å™ªå¾ªç¯ï¼
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # 
                    # ã€ä¸ºä»€ä¹ˆè¦ breakï¼Ÿã€‘
                    # è¿™æ˜¯ Self-Forcing çš„æ ¸å¿ƒè®¾è®¡ï¼è®©æˆ‘è¯¦ç»†è§£é‡Šï¼š
                    # 
                    # å‡è®¾å»å™ªæ­¥éª¤æ˜¯ [1000, 750, 500, 250]ï¼Œexit_flag = 1ï¼ˆå³åœ¨ç¬¬ 2 æ­¥é€€å‡ºï¼‰ï¼š
                    # 
                    # æ­£å¸¸æ¨ç†æµç¨‹ï¼ˆ4 æ­¥å®Œæ•´å»å™ªï¼‰ï¼š
                    #   å™ªå£° x_1000 â†’ æ¨¡å‹ â†’ x_750 â†’ æ¨¡å‹ â†’ x_500 â†’ æ¨¡å‹ â†’ x_250 â†’ æ¨¡å‹ â†’ æ¸…æ™°å›¾åƒ x_0
                    # 
                    # Self-Forcing è®­ç»ƒæµç¨‹ï¼ˆåœ¨ç¬¬ 2 æ­¥é€€å‡ºï¼‰ï¼š
                    #   å™ªå£° x_1000 â†’ æ¨¡å‹ â†’ x_750 â†’ ã€é€€å‡ºï¼ç›´æ¥ç”¨ x_750 ä½œä¸ºè¿™ä¸ª Block çš„è¾“å‡ºã€‘
                    # 
                    # é—®é¢˜ï¼šx_750 è¿˜å¾ˆæ¨¡ç³Šï¼ˆè¿˜æœ‰å™ªå£°ï¼‰ï¼Œä¸æ˜¯å®Œç¾çš„å›¾åƒï¼Œä¸ºä»€ä¹ˆè¦ç”¨å®ƒï¼Ÿ
                    # 
                    # ç­”æ¡ˆï¼šè¿™æ­£æ˜¯ Self-Forcing çš„ç²¾é«“ï¼
                    # 
                    # 1. ã€è®­ç»ƒæ¨ç†ä¸€è‡´æ€§ã€‘
                    #    - æ¨ç†æ—¶ï¼Œå½“å‰å¸§çš„è¾“å‡ºä¼šä½œä¸ºä¸‹ä¸€å¸§çš„ KV Cache è¾“å…¥
                    #    - å¦‚æœå½“å‰å¸§æœ‰è¯¯å·®ï¼Œè¿™ä¸ªè¯¯å·®ä¼šä¼ æ’­åˆ°ä¸‹ä¸€å¸§
                    #    - ä¼ ç»Ÿè®­ç»ƒä½¿ç”¨ Ground Truthï¼Œæ¨¡å‹æ²¡å­¦è¿‡å¦‚ä½•å¤„ç†è¯¯å·®
                    #    - Self-Forcing æ•…æ„ä½¿ç”¨ä¸å®Œç¾çš„ä¸­é—´ç»“æœï¼Œè®©æ¨¡å‹å­¦ä¼š"å®¹é”™"
                    # 
                    # 2. ã€éšæœºæ€§å¸¦æ¥é²æ£’æ€§ã€‘
                    #    - exit_flag æ˜¯éšæœºçš„ï¼Œæœ‰æ—¶åœ¨ step 0 é€€å‡ºï¼ˆå™ªå£°å¾ˆå¤§ï¼‰ï¼Œæœ‰æ—¶åœ¨ step 3 é€€å‡ºï¼ˆåŸºæœ¬æ¸…æ™°ï¼‰
                    #    - æ¨¡å‹è¢«è¿«å­¦ä¼šå¤„ç†å„ç§è´¨é‡çº§åˆ«çš„è¾“å…¥
                    #    - è¿™å¤§å¤§å¢å¼ºäº†æ¨¡å‹åœ¨æ¨ç†æ—¶çš„ç¨³å®šæ€§
                    # 
                    # 3. ã€è®¡ç®—æ•ˆç‡ã€‘
                    #    - ä¸éœ€è¦åƒçœŸæ­£æ¨ç†é‚£æ ·è·‘å®Œæ‰€æœ‰ 4 æ­¥
                    #    - å¹³å‡åªéœ€è¦è·‘ ~2 æ­¥å°±é€€å‡ºï¼ŒèŠ‚çœäº†ä¸€åŠçš„è®¡ç®—
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    break

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Step 3.2: è®°å½•è¾“å‡º
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            output[:, current_start_frame:current_start_frame + current_num_frames] = denoised_pred

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Step 3.3: æ›´æ–° KV Cache (å…³é”®!)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ç”¨ç”Ÿæˆçš„ Clearn Frame (æˆ–è€…åŠ äº†å¾®é‡ Context Noise çš„ Frame) 
            # ä»¥ t=0 å†æ¬¡è¿è¡Œç”Ÿæˆå™¨ï¼Œç›®çš„æ˜¯æ›´æ–° kv_cache1ï¼Œä¾›ä¸‹ä¸€ä¸ª Block ä½¿ç”¨ã€‚
            context_timestep = torch.ones_like(timestep) * self.context_noise
            
            # æ·»åŠ å¾®é‡å™ªå£° (å¦‚æœé…ç½®äº† context_noise) é˜²æ­¢è¿‡æ‹Ÿåˆ
            denoised_pred = self.scheduler.add_noise(
                denoised_pred.flatten(0, 1),
                torch.randn_like(denoised_pred.flatten(0, 1)),
                context_timestep * torch.ones(
                    [batch_size * current_num_frames], device=noise.device, dtype=torch.long)
            ).unflatten(0, denoised_pred.shape[:2])
            
            # å¿…é¡»ç”¨ no_gradï¼Œå› ä¸ºæˆ‘ä»¬ä¸å¸Œæœ›æ¢¯åº¦é€šè¿‡ KV Cache ä¼ æ’­åˆ°ä¸Šä¸€ä¸ª Block
            # æˆ‘ä»¬åªè®­ç»ƒå½“å‰ Block çš„ç”Ÿæˆèƒ½åŠ›ï¼Œåˆ©ç”¨ä¹‹å‰çš„ Context
            with torch.no_grad():
                self.generator(
                    noisy_image_or_video=denoised_pred,
                    conditional_dict=conditional_dict,
                    timestep=context_timestep,
                    kv_cache=self.kv_cache1, # â† æ›´æ–° Cache
                    crossattn_cache=self.crossattn_cache,
                    current_start=current_start_frame * self.frame_seq_length
                )

            # æ›´æ–°å½“å‰å¸§æŒ‡é’ˆ
            current_start_frame += current_num_frames

        # Step 3.5: è¿”å›å»å™ªæ—¶é—´æ­¥ä¿¡æ¯ (ç”¨äº Loss è®¡ç®—)
        # å‘Šè¯‰ Loss å‡½æ•°å½“å‰é‡‡ç”¨äº†å“ªä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹ç»“æœ
        if not self.same_step_across_blocks:
            denoised_timestep_from, denoised_timestep_to = None, None
        elif exit_flags[0] == len(self.denoising_step_list) - 1:
            denoised_timestep_to = 0
            denoised_timestep_from = 1000 - torch.argmin(
                (self.scheduler.timesteps.cuda() - self.denoising_step_list[exit_flags[0]].cuda()).abs(), dim=0).item()
        else:
            denoised_timestep_to = 1000 - torch.argmin(
                (self.scheduler.timesteps.cuda() - self.denoising_step_list[exit_flags[0] + 1].cuda()).abs(), dim=0).item()
            denoised_timestep_from = 1000 - torch.argmin(
                (self.scheduler.timesteps.cuda() - self.denoising_step_list[exit_flags[0]].cuda()).abs(), dim=0).item()

        if return_sim_step:
            return output, denoised_timestep_from, denoised_timestep_to, exit_flags[0] + 1

        return output, denoised_timestep_from, denoised_timestep_to

    def _initialize_kv_cache(self, batch_size, dtype, device):
        """
        åˆå§‹åŒ– Per-GPU KV cacheã€‚
        ç»“æ„: List[Dict]ï¼Œåˆ—è¡¨é•¿åº¦ä¸º Transformer å±‚æ•°ã€‚
        Dict åŒ…å« 'k', 'v' ä»¥åŠç´¢å¼•æŒ‡é’ˆã€‚
        """
        kv_cache1 = []

        for _ in range(self.num_transformer_blocks):
            kv_cache1.append({
                "k": torch.zeros([batch_size, self.kv_cache_size, 12, 128], dtype=dtype, device=device),
                "v": torch.zeros([batch_size, self.kv_cache_size, 12, 128], dtype=dtype, device=device),
                "global_end_index": torch.tensor([0], dtype=torch.long, device=device), # å…¨å±€ token ç´¢å¼•
                "local_end_index": torch.tensor([0], dtype=torch.long, device=device)   # å±€éƒ¨ token ç´¢å¼•
            })

        self.kv_cache1 = kv_cache1  # always store the clean cache

    def _initialize_crossattn_cache(self, batch_size, dtype, device):
        """
        åˆå§‹åŒ– Cross-Attention Cache (ç”¨äºç¼“å­˜æ–‡æœ¬ Context çš„ Attention)
        """
        crossattn_cache = []

        for _ in range(self.num_transformer_blocks):
            crossattn_cache.append({
                "k": torch.zeros([batch_size, 512, 12, 128], dtype=dtype, device=device),
                "v": torch.zeros([batch_size, 512, 12, 128], dtype=dtype, device=device),
                "is_init": False
            })
        self.crossattn_cache = crossattn_cache
